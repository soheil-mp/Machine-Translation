{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center;\">Machine Translation</h1>\n",
    "<h3 style=\"text-align:center;\">Encoder-Decoder with Teacher Forcing</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Initial Deployment\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import nltk, re, tqdm, keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Load Dataset\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: \n",
      " ['new jersey is sometimes quiet during autumn , and it is snowy in april .', 'the united states is usually chilly during july , and it is usually freezing in november .']\n",
      "\n",
      "French: \n",
      " [\"new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\", 'les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .']\n"
     ]
    }
   ],
   "source": [
    "# Load the english dataset\n",
    "with open(\"./dataset/en.txt\", encoding='utf-8') as f:\n",
    "    en = f.read().split(\"\\n\")\n",
    "\n",
    "# Load the french dataset\n",
    "with open(\"./dataset/fr.txt\", encoding='utf-8') as f:\n",
    "    fr = f.read().split(\"\\n\")\n",
    "\n",
    "# Report\n",
    "print(\"English: \\n\", en[:2])\n",
    "print(\"\\nFrench: \\n\", fr[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Text Processing & Feature Extraction\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for preprocessing the texts\n",
    "def text_preprocessing(text):\n",
    "\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove unnecessary characters\n",
    "    text = re.sub(r\"[/.,|?><;:±!@#$%^&*()_+=-]\", \" \", text)\n",
    "\n",
    "    # Remove extra empty spaces\n",
    "    text = \" \".join(text.split())\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m███████████████████████████████████████████████████\u001b[0m| 137861/137861 [00:00<00:00, 410220.30it/s]\u001b[0m\n",
      "100%|\u001b[34m███████████████████████████████████████████████████\u001b[0m| 137861/137861 [00:00<00:00, 342350.05it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: \n",
      " ['new jersey is sometimes quiet during autumn and it is snowy in april'\n",
      " 'the united states is usually chilly during july and it is usually freezing in november']\n",
      "\n",
      "French: \n",
      " [\"new jersey est parfois calme pendant l' automne et il est neigeux en avril\"\n",
      " 'les états unis est généralement froid en juillet et il gèle habituellement en novembre']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the texts\n",
    "en = np.array([text_preprocessing(i) for i in tqdm.tqdm(en, ncols=100, colour=\"blue\")])\n",
    "fr = np.array([text_preprocessing(i) for i in tqdm.tqdm(fr, ncols=100, colour=\"blue\")])\n",
    "\n",
    "# Report\n",
    "print(\"English: \\n\", en[:2])\n",
    "print(\"\\nFrench: \\n\", fr[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for creating Word2Int and Int2Word\n",
    "def prepare_word_dictionay(list_of_texts, language):\n",
    "\n",
    "    # Unique tokens\n",
    "    text = \" \".join(list_of_texts.ravel()).lower()                  # Convert list of strings into one string\n",
    "    tokens = nltk.tokenize.word_tokenize(text, language=language)   # Tokenize\n",
    "    unique_tokens = np.unique(tokens)                               # Unique tokens\n",
    "\n",
    "    # Initialize Word2Int\n",
    "    word2int = {}\n",
    "\n",
    "    # Add necessary tags  \n",
    "    word2int[\"<SOS>\"] = 1        # Start-of-sequence <SOS> tag\n",
    "    word2int[\"<EOS>\"] = 2        # End-of-sequence <EOS> tag\n",
    "    word2int[\"<UNK>\"] = 3        # Unknown <UNK> tag\n",
    "\n",
    "    # Loop over unique tokens\n",
    "    for i_token in tqdm.tqdm(unique_tokens, ncols=100, colour=\"blue\"):\n",
    "\n",
    "        # Add to Word2Int\n",
    "        word2int[i_token] = max(word2int.values())+1\n",
    "\n",
    "    # Make Int2Word\n",
    "    int2word = {idx: word for word, idx in word2int.items()}\n",
    "\n",
    "    return word2int, int2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m█████████████████████████████████████████████████████████████████████\u001b[0m| 197/197 [00:00<?, ?it/s]\u001b[0m\n",
      "100%|\u001b[34m█████████████████████████████████████████████████████████\u001b[0m| 345/345 [00:00<00:00, 344286.20it/s]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Create word2int and int2word\n",
    "word2int_en, int2word_en = prepare_word_dictionay(list_of_texts=en, language=\"english\")\n",
    "word2int_fr, int2word_fr = prepare_word_dictionay(list_of_texts=fr, language=\"french\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding function; For converting words to numerical values\n",
    "def label_encoding(text, word2int, language):\n",
    "\n",
    "    # Tokenize\n",
    "    tokens = nltk.tokenize.word_tokenize(text, language=language)\n",
    "\n",
    "    # Add staring/ending tag\n",
    "    tokens.insert(0, \"<SOS>\")\n",
    "    tokens.insert(len(tokens), \"<EOS>\")\n",
    "\n",
    "    # Initialize a list\n",
    "    encoded_tokens = []\n",
    "\n",
    "    # Loop over tokens\n",
    "    for i in tokens:\n",
    "\n",
    "        # Append idx if it exist\n",
    "        try: encoded_tokens.append(word2int[i])\n",
    "\n",
    "        # Append <UNK> if it doesn't exist\n",
    "        except: encoded_tokens.append(word2int[\"<UNK>\"])\n",
    "\n",
    "    return encoded_tokens\n",
    "\n",
    "\n",
    "# Label decoding function; For converting numerical values to words\n",
    "def label_decoding(tokens, int2word):\n",
    "\n",
    "    # Initialize a list\n",
    "    decoded_tokens = []\n",
    "\n",
    "    # Loop over tokens\n",
    "    for i in tokens:\n",
    "\n",
    "        # Append word if it exist\n",
    "        try: decoded_tokens.append(int2word[i])\n",
    "\n",
    "        # Append <UNK> if it doesn't exist\n",
    "        except: decoded_tokens.append(\"<UNK>\")\n",
    "\n",
    "    return decoded_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m████████████████████████████████████████████████████\u001b[0m| 137861/137861 [00:10<00:00, 12705.15it/s]\u001b[0m\n",
      "100%|\u001b[34m████████████████████████████████████████████████████\u001b[0m| 137861/137861 [00:11<00:00, 12407.72it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: \n",
      " [[1, 123, 92, 89, 158, 141, 53, 16, 7, 90, 89, 157, 87, 12, 2]]\n",
      "\n",
      "French: \n",
      " [[1, 209, 154, 109, 229, 53, 232, 157, 4, 32, 110, 145, 109, 208, 101, 37, 2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Label encode the texts\n",
    "en_label_encoded = [label_encoding(i, language=\"english\", word2int=word2int_en) for i in tqdm.tqdm(en, ncols=100, colour=\"blue\", total=en.shape[0])]\n",
    "fr_label_encoded = [label_encoding(i, language=\"french\", word2int=word2int_fr) for i in tqdm.tqdm(fr, ncols=100, colour=\"blue\", total=fr.shape[0])]\n",
    "\n",
    "# Report\n",
    "print(\"English: \\n\", en_label_encoded[:1])\n",
    "print(\"\\nFrench: \\n\", fr_label_encoded[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for padding the sequence\n",
    "def padding(label_encoded_seq, max_len):\n",
    "\n",
    "    # Pad the sequences\n",
    "    padded_seq = tf.keras.preprocessing.sequence.pad_sequences(sequences=label_encoded_seq, maxlen=max_len, \n",
    "                                                               padding=\"post\", truncating=\"post\")\n",
    "\n",
    "    return padded_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of int tokens EN:  (137861, 25)\n",
      "Shape of int tokens FR:  (137861, 25)\n"
     ]
    }
   ],
   "source": [
    "# Maximum length for padding\n",
    "max_len = max(max([len(i) for i in en_label_encoded]), max([len(i) for i in fr_label_encoded]))\n",
    "\n",
    "# Pad the sequences\n",
    "en_label_encoded = padding(en_label_encoded, max_len) \n",
    "fr_label_encoded = padding(fr_label_encoded, max_len) \n",
    "\n",
    "# Report\n",
    "print(\"Shape of int tokens EN: \", en_label_encoded.shape)\n",
    "print(\"Shape of int tokens FR: \", fr_label_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding; Function for converting numerical values to binary vectors\n",
    "def one_hot_encoding(label_encoded_seq, length):\n",
    "\n",
    "    # Initialize a list for one hot encoded\n",
    "    one_hot_encoded = []\n",
    "    \n",
    "    # Loop over each token in the sequence\n",
    "    for i_token in label_encoded_seq:\n",
    "\n",
    "        # Initialize zero vector\n",
    "        #token = np.zeros(shape=length)\n",
    "        token = [0 for _ in range(length)]\n",
    "        \n",
    "        # Set one\n",
    "        token[i_token] = 1\n",
    "\n",
    "        # Append to the list\n",
    "        one_hot_encoded.append(token)\n",
    "\n",
    "    #return np.array(one_hot_encoded)\n",
    "    return one_hot_encoded\n",
    "\n",
    "\n",
    "# Function for one hot decoding\n",
    "def one_hot_decoding(tokens):\n",
    "\n",
    "    # Initialize a list for one hot decoded\n",
    "    one_hot_decoded = []\n",
    "        \n",
    "    # Loop over each token in the sequence\n",
    "    for i_token in tokens:\n",
    "\n",
    "        # Append to the list\n",
    "        one_hot_decoded.append(np.argmax(i_token))\n",
    "\n",
    "    #return np.array(one_hot_decoded)\n",
    "    return one_hot_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m█████████████████████████████████████████████████████\u001b[0m| 137861/137861 [00:32<00:00, 4246.57it/s]\u001b[0m\n",
      "100%|\u001b[34m█████████████████████████████████████████████████████\u001b[0m| 137861/137861 [01:05<00:00, 2089.37it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of int tokens EN:  (137861, 25, 201)\n",
      "Shape of int tokens FR:  (137861, 25, 349)\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding\n",
    "en_one_hot_encoded = np.array([one_hot_encoding(i, length=len(word2int_en)+1) for i in tqdm.tqdm(en_label_encoded, ncols=100, colour=\"blue\")])\n",
    "fr_one_hot_encoded = np.array([one_hot_encoding(i, length=len(word2int_fr)+1) for i in tqdm.tqdm(fr_label_encoded, ncols=100, colour=\"blue\")])\n",
    "\n",
    "# Report\n",
    "print(\"Shape of int tokens EN: \", en_one_hot_encoded.shape)\n",
    "print(\"Shape of int tokens FR: \", fr_one_hot_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for splitting the dataset into training/testing set\n",
    "def split_train_test(x, y, train_ratio=0.95):\n",
    "\n",
    "    # Find the dividing index\n",
    "    #div_idx = int(x.shape[0]*train_ratio)\n",
    "    div_idx = int(len(x)*train_ratio)\n",
    "\n",
    "    # Training set\n",
    "    x_train, y_train = x[:div_idx], y[:div_idx]\n",
    "\n",
    "    # Testing set\n",
    "    x_test, y_test = x[div_idx:], y[div_idx:]\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x-train shape:  (130967, 25, 201)\n",
      "y-train Shape:  (130967, 25, 349)\n",
      "x-test Shape:   (6894, 25, 201)\n",
      "y-test Shape:   (6894, 25, 349)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing set\n",
    "x_train, y_train, x_test, y_test = split_train_test(x=en_one_hot_encoded, y=fr_one_hot_encoded, train_ratio=0.95)\n",
    "\n",
    "# Report\n",
    "print(\"x-train shape: \", x_train.shape) \n",
    "print(\"y-train Shape: \", y_train.shape)\n",
    "print(\"x-test Shape:  \", x_test.shape)\n",
    "print(\"y-test Shape:  \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Model Construction and Training\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Input Data - (130967, 25, 201): \n",
      "[[0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Encoder input data\n",
    "encoder_input_data  = x_train\n",
    "\n",
    "# Report\n",
    "print(f\"Encoder Input Data - {encoder_input_data.shape}: \")\n",
    "print(encoder_input_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decoder Input Data - (130967, 25, 349): \n",
      "[[0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Decoder input data\n",
    "decoder_input_data  = y_train\n",
    "\n",
    "# Report\n",
    "print(f\"\\nDecoder Input Data - {decoder_input_data.shape}: \")\n",
    "print(decoder_input_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m█████████████████████████████████████████████████████\u001b[0m| 130967/130967 [01:45<00:00, 1243.54it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decoder Output Data - (130967, 25, 349): \n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Decoder output data\n",
    "decoder_output_data = [np.append(i[1:], [0]) for i in fr_label_encoded]      # Shift tokens by 1\n",
    "decoder_output_data = decoder_output_data[:x_train.shape[0]]                 # Same size as x_train\n",
    "decoder_output_data = np.array([one_hot_encoding(i, length=len(word2int_fr)+1) for i in tqdm.tqdm(decoder_output_data, ncols=100, colour=\"blue\")])\n",
    "\n",
    "# Report\n",
    "print(f\"\\nDecoder Output Data - {decoder_output_data.shape}: \")\n",
    "print(decoder_output_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_encoder_tokens = len(word2int_en)+1\n",
    "num_decoder_tokens = len(word2int_fr)+1\n",
    "latent_dim = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder input\n",
    "encoder_inputs = tf.keras.layers.Input(shape=(None, num_encoder_tokens), \n",
    "                                       name=\"encoder input\")\n",
    "\n",
    "# Encoder LSTM\n",
    "encoder = tf.keras.layers.LSTM(latent_dim,                 # latent_dim represents the dimensionality of context vector\n",
    "                               return_sequences=False, \n",
    "                               return_state=True, \n",
    "                               name=\"encoder_LSTM\") \n",
    "\n",
    "# Feed input to LSTM\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "# Context Vector (i.e. last hidden states and cell states of encoder)\n",
    "context_vector = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder input\n",
    "decoder_inputs = tf.keras.layers.Input(shape=(None, num_decoder_tokens), \n",
    "                                       name=\"decoder input\")\n",
    "\n",
    "# Decoder LSTM\n",
    "decoder_lstm = tf.keras.layers.LSTM(latent_dim, \n",
    "                                    return_sequences=True, \n",
    "                                    return_state=True, \n",
    "                                    name=\"decoder_LSTM\")\n",
    "\n",
    "# Feed input to LSTM\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=context_vector)    # Initialize states with Context Vecotr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output\n",
    "decoder_dense = tf.keras.layers.Dense(num_decoder_tokens,         #num_decoder_tokens,   # TODO: The problem should be here\n",
    "                                      activation='softmax', \n",
    "                                      name=\"output\")\n",
    "\n",
    "# Feed decoder to output\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder input (InputLayer)     [(None, None, 201)]  0           []                               \n",
      "                                                                                                  \n",
      " decoder input (InputLayer)     [(None, None, 349)]  0           []                               \n",
      "                                                                                                  \n",
      " encoder_LSTM (LSTM)            [(None, 512),        1462272     ['encoder input[0][0]']          \n",
      "                                 (None, 512),                                                     \n",
      "                                 (None, 512)]                                                     \n",
      "                                                                                                  \n",
      " decoder_LSTM (LSTM)            [(None, None, 512),  1765376     ['decoder input[0][0]',          \n",
      "                                 (None, 512),                     'encoder_LSTM[0][1]',           \n",
      "                                 (None, 512)]                     'encoder_LSTM[0][2]']           \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, None, 349)    179037      ['decoder_LSTM[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,406,685\n",
      "Trainable params: 3,406,685\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model\n",
    "model = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "\n",
    "# Summary\n",
    "print(model.summary())\n",
    "\n",
    "# Plot the model\n",
    "keras.utils.vis_utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "819/819 [==============================] - 95s 107ms/step - loss: 0.8977 - accuracy: 0.7547 - val_loss: 0.4544 - val_accuracy: 0.8421\n",
      "Epoch 2/10\n",
      "819/819 [==============================] - 85s 103ms/step - loss: 0.3771 - accuracy: 0.8672 - val_loss: 0.3049 - val_accuracy: 0.8933\n",
      "Epoch 3/10\n",
      "819/819 [==============================] - 85s 103ms/step - loss: 0.2040 - accuracy: 0.9304 - val_loss: 0.1090 - val_accuracy: 0.9645\n",
      "Epoch 4/10\n",
      "819/819 [==============================] - 85s 103ms/step - loss: 0.0543 - accuracy: 0.9839 - val_loss: 0.0373 - val_accuracy: 0.9886\n",
      "Epoch 5/10\n",
      "819/819 [==============================] - 85s 104ms/step - loss: 0.0316 - accuracy: 0.9901 - val_loss: 0.0352 - val_accuracy: 0.9888\n",
      "Epoch 6/10\n",
      "819/819 [==============================] - 85s 103ms/step - loss: 0.0207 - accuracy: 0.9935 - val_loss: 0.0301 - val_accuracy: 0.9901\n",
      "Epoch 7/10\n",
      "819/819 [==============================] - 84s 103ms/step - loss: 0.0179 - accuracy: 0.9943 - val_loss: 0.0189 - val_accuracy: 0.9939\n",
      "Epoch 8/10\n",
      "819/819 [==============================] - 85s 103ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.0189 - val_accuracy: 0.9939\n",
      "Epoch 9/10\n",
      "819/819 [==============================] - 85s 103ms/step - loss: 0.0129 - accuracy: 0.9958 - val_loss: 0.0145 - val_accuracy: 0.9955\n",
      "Epoch 10/10\n",
      "819/819 [==============================] - 84s 103ms/step - loss: 0.0119 - accuracy: 0.9960 - val_loss: 0.0136 - val_accuracy: 0.9957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14b40b6c160>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit([encoder_input_data, decoder_input_data],\n",
    "           decoder_output_data,\n",
    "           epochs=10,\n",
    "           batch_size=128,\n",
    "           validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"./saved models/model_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model got loaded.\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = tf.keras.models.load_model(\"./saved models/model_2.h5\")\n",
    "print(\"Model got loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Inference\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder input (InputLayer)  [(None, None, 201)]       0         \n",
      "                                                                 \n",
      " encoder_LSTM (LSTM)         [(None, 512),             1462272   \n",
      "                              (None, 512),                       \n",
      "                              (None, 512)]                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,462,272\n",
      "Trainable params: 1,462,272\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Encoder input\n",
    "encoder_inputs = tf.keras.layers.Input(shape=(None, num_encoder_tokens), \n",
    "                                       name=\"encoder input\")\n",
    "\n",
    "# Feed input to LSTM\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "# Context Vector (i.e. last hidden states and cell states of encoder)\n",
    "context_vector = [state_h, state_c]\n",
    "\n",
    "# Encoder model\n",
    "encoder_model = tf.keras.Model(encoder_inputs, context_vector)\n",
    "\n",
    "# Report\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input - hidden state\n",
    "decoder_state_input_h = keras.layers.Input(shape=(latent_dim,), name=\"hidden state input\")\n",
    "\n",
    "# Input - cell state\n",
    "decoder_state_input_c = keras.layers.Input(shape=(latent_dim,), name=\"cell state input\")\n",
    "\n",
    "# Save the inputs\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# Decoder LSTM\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "\n",
    "# Save the states\n",
    "decoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " decoder input (InputLayer)     [(None, None, 349)]  0           []                               \n",
      "                                                                                                  \n",
      " hidden state input (InputLayer  [(None, 512)]       0           []                               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " cell state input (InputLayer)  [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " decoder_LSTM (LSTM)            [(None, None, 512),  1765376     ['decoder input[0][0]',          \n",
      "                                 (None, 512),                     'hidden state input[0][0]',     \n",
      "                                 (None, 512)]                     'cell state input[0][0]']       \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, None, 349)    179037      ['decoder_LSTM[1][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,944,413\n",
      "Trainable params: 1,944,413\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Output dense\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Construct model\n",
    "decoder_model = tf.keras.Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "\n",
    "# Report\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    \n",
    "    # Encoder prediction (get context vector)\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Initialize the target sequence with zeros - shape of (1, 1, NUM_DECODER_TOKEN)\n",
    "    target_seq = np.zeros(shape=(1, 1, num_decoder_tokens))\n",
    "\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, 0] = word2int_en[\"<SOS>\"]\n",
    "\n",
    "    # Initialize the maximum decoder length\n",
    "    max_decoder_length = decoder_output_data.shape[-1]\n",
    "\n",
    "    # Initialize the stop condition\n",
    "    stop_condition = False\n",
    "\n",
    "    # Initialize the decoded sentence\n",
    "    decoded_sentence = []\n",
    "\n",
    "    # While stop condition is false\n",
    "    while not stop_condition:\n",
    "\n",
    "        # Decoder prediction\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Find the maximum index value\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "\n",
    "        # Add the predicted int to output sequence\n",
    "        decoded_sentence.append(sampled_token_index) \n",
    "\n",
    "        # Exit condition\n",
    "        #   1. Hitting maximum length\n",
    "        #   2. Finding stop character\n",
    "        if (sampled_token_index==word2int_en[\"<EOS>\"]) or (len(decoded_sentence)==max_decoder_length):\n",
    "\n",
    "            # Set stop condition to true\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros(shape=(1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states (context vector) \n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence, target_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for inference\n",
    "def inference(model, text):\n",
    "\n",
    "    # Label encode\n",
    "    encoded = label_encoding(text, word2int_en, \"english\")\n",
    "\n",
    "    # Padding\n",
    "    encoded = padding([encoded], max_len)[0]\n",
    "\n",
    "    # One hot encoding\n",
    "    encoded = one_hot_encoding(encoded, length=len(word2int_en)+1)\n",
    "\n",
    "    # Expand first dimension\n",
    "    encoded = np.expand_dims(encoded, 0)\n",
    "\n",
    "    # Predict\n",
    "    prediction, _ = decode_sequence(encoded)\n",
    "\n",
    "    # Label decoding\n",
    "    decoded = \" \".join(label_decoding(prediction, int2word_fr))\n",
    "\n",
    "    # Remove tags\n",
    "    for i_token in [\"<SOS>\", \"<EOS>\", \"<UNK>\"]: decoded = decoded.replace(i_token, \"\").strip()\n",
    "\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:        new jersey is sometimes quiet during autumn and it is snowy in april\n",
      "PREDICTION:   new jersey est parfois calme pendant l ' automne et il est neigeux en avril\n",
      "TRUE OUTPUT:  new jersey est parfois calme pendant l' automne et il est neigeux en avril\n"
     ]
    }
   ],
   "source": [
    "# Predict a sentence\n",
    "input_text = \"new jersey is sometimes quiet during autumn and it is snowy in april\"\n",
    "prediction = inference(model=model, text=input_text)\n",
    "true_output = \"new jersey est parfois calme pendant l' automne et il est neigeux en avril\"\n",
    "\n",
    "# Report\n",
    "print(\"INPUT:       \", input_text)\n",
    "print(\"PREDICTION:  \", prediction)\n",
    "print(\"TRUE OUTPUT: \", true_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### THE END"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4bf5a16b79f3cb90985e3628257d567fbd7649cb1685a1c31906a530b639e1e3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('prime')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
